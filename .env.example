# AgentLens Environment Configuration
# Copy this file to .env and fill in values

# =============================================================================
# INFERENCE ENGINE
# =============================================================================
# Model to use (huggingface model ID or local path)
INFERENCE_MODEL=meta-llama/Meta-Llama-3-8B-Instruct

# Quantization (none, awq, gptq, squeezellm)
INFERENCE_QUANTIZATION=none

# Max model length (context window)
INFERENCE_MAX_MODEL_LEN=8192

# GPU memory utilization (0.0-1.0)
INFERENCE_GPU_MEMORY_UTILIZATION=0.85

# =============================================================================
# FALLBACK MODEL (for low memory or CPU mode)
# =============================================================================
FALLBACK_MODEL=microsoft/Phi-3-mini-4k-instruct

# =============================================================================
# METRICS
# =============================================================================
PROMETHEUS_PORT=9090
GRAFANA_PORT=3001

# Metrics scrape interval (seconds)
METRICS_SCRAPE_INTERVAL=5

# =============================================================================
# DASHBOARD
# =============================================================================
DASHBOARD_PORT=3000

# =============================================================================
# VECTOR DATABASE
# =============================================================================
POSTGRES_USER=agentlens
POSTGRES_PASSWORD=changeme
POSTGRES_DB=agentlens

# =============================================================================
# ORCHESTRATOR
# =============================================================================
# Max concurrent agents
MAX_CONCURRENT_AGENTS=2

# Agent timeout (seconds)
AGENT_TIMEOUT=60

# =============================================================================
# MODE
# =============================================================================
# gpu or cpu
AGENTLENS_MODE=gpu
